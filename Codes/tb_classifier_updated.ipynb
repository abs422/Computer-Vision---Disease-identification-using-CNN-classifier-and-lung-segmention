{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNfyVTekrmPz"
      },
      "outputs": [],
      "source": [
        "# Initial TB classifier with 3 classes\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "faFnNO_0ruhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "id": "Hk9ptpeDryBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"normal\", \"other_tb\", \"ptb\"]"
      ],
      "metadata": {
        "id": "4vuMEL6yCOTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "jwnpws8ZVxqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "    \"labels\": \"inferred\",\n",
        "    \"label_mode\": \"categorical\",\n",
        "    \"batch_size\": 32,\n",
        "    \"image_size\": (256, 256),\n",
        "    \"seed\": 1,\n",
        "    \"validation_split\": .2,\n",
        "    \"class_names\": classes\n",
        "}"
      ],
      "metadata": {
        "id": "9tNwLJEgVzLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/classifier_input\",\n",
        "    subset=\"training\",\n",
        "    **args\n",
        ")\n",
        "\n",
        "test = tf.keras.utils.image_dataset_from_directory(\n",
        "  \"/content/drive/MyDrive/classifier_input\",\n",
        "  subset=\"validation\",\n",
        "    **args\n",
        ")"
      ],
      "metadata": {
        "id": "qILpSoaLV09e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first = train.take(1)\n",
        "first"
      ],
      "metadata": {
        "id": "mJnN4DrSnWZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = list(first)[0]\n",
        "first_image = images[0]"
      ],
      "metadata": {
        "id": "QFaYx7k7nYfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_image[:3,:3,0]"
      ],
      "metadata": {
        "id": "2REeZOb8nbeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "Image.fromarray(images[0].numpy().astype(\"uint8\"))"
      ],
      "metadata": {
        "id": "lDurDDdYncl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test = test.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "2MfG7fCQV4xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "# Making a simple sequential model\n",
        "model = Sequential([\n",
        "  tf.keras.layers.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(256,256,3)),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(len(classes))\n",
        "])"
      ],
      "metadata": {
        "id": "KwKAZvMUV6YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "kZEF8RJNV8RO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train,\n",
        "    validation_data=test,\n",
        "    epochs=10,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "mBBvJvzEV-C2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "GQl-yuiJV-3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "history_df = pd.DataFrame.from_dict(history.history)\n",
        "history_df[[\"accuracy\", \"val_accuracy\"]].plot()\n"
      ],
      "metadata": {
        "id": "U0-ke63bWA26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(network, epochs=15):\n",
        "    model = Sequential(network)\n",
        "\n",
        "    model.compile(optimizer='sgd',\n",
        "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(\n",
        "      train,\n",
        "      validation_data=test,\n",
        "      epochs=epochs\n",
        "    )\n",
        "    history_df = pd.DataFrame.from_dict(history.history)\n",
        "    return history_df, model"
      ],
      "metadata": {
        "id": "5bP9vqmYWCwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = [\n",
        "  tf.keras.layers.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 4, padding='same', activation='relu', input_shape=(256,256,3)),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 4, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 4, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(len(classes))\n",
        "]\n",
        "\n",
        "history_df, model = train_model(network)"
      ],
      "metadata": {
        "id": "2zfSWhrHWEhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_df[[\"accuracy\", \"val_accuracy\"]].plot()"
      ],
      "metadata": {
        "id": "t7mHIWLNWGdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "EHyaRoC3r0aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"vertical\", seed=1),\n",
        "      layers.RandomRotation(0.2, seed=1),\n",
        "    layers.RandomZoom(0.2, seed=1),\n",
        "  ]\n",
        ")\n",
        "\n",
        "\n",
        "full_network = [\n",
        "    data_augmentation\n",
        "] + network\n",
        "\n",
        "history_df, model = train_model(full_network, epochs=40)"
      ],
      "metadata": {
        "id": "UvSldCMmWILw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_df[[\"accuracy\", \"val_accuracy\"]].plot()"
      ],
      "metadata": {
        "id": "jYevdydwWKAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "5_ePzyv0sP9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(test)"
      ],
      "metadata": {
        "id": "avSxwdfeWL4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "predicted_class = np.argmax(preds, axis=1)"
      ],
      "metadata": {
        "id": "vcZJB_E6WNi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_labels = np.concatenate([y for x, y in test], axis=0)"
      ],
      "metadata": {
        "id": "OAl8JDm1WPAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "actual_image = [x.numpy().astype(\"uint8\") for x, y in test]\n",
        "actual_image = list(itertools.chain.from_iterable(actual_image))\n",
        "actual_image = [Image.fromarray(a) for a in actual_image]"
      ],
      "metadata": {
        "id": "0aX03vv-WQi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_class = np.argmax(actual_labels, axis=1)"
      ],
      "metadata": {
        "id": "E-aNV8HNWSSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = pd.DataFrame(zip(predicted_class, actual_class, actual_image), columns=[\"prediction\", \"actual\", \"image\"])"
      ],
      "metadata": {
        "id": "_09i7loOWT7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df[\"prediction\"] = pred_df[\"prediction\"].apply(lambda x: classes[x])\n",
        "pred_df[\"actual\"] = pred_df[\"actual\"].apply(lambda x: classes[x])"
      ],
      "metadata": {
        "id": "TaRVRXh7WVyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import io\n",
        "\n",
        "def image_formatter(img):\n",
        "    with io.BytesIO() as buffer:\n",
        "        img.save(buffer, 'png')\n",
        "        img_str = base64.b64encode(buffer.getvalue()).decode()\n",
        "        return f'{img_str}\">'\n",
        "\n",
        "pred_df.head(10).style.format({'image': image_formatter})"
      ],
      "metadata": {
        "id": "r3cvYhZqWdm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "# Predicted values\n",
        "y_pred = pred_df[\"prediction\"]\n",
        "# Actual values\n",
        "y_act = pred_df[\"actual\"]\n",
        "# Printing the confusion matrix\n",
        "# The columns will show the instances predicted for each label,\n",
        "# and the rows will show the actual number of instances for each label.\n",
        "print(metrics.confusion_matrix(y_act, y_pred, labels=[\"normal\", \"other_tb\", \"ptb\"]))\n",
        "# Printing the precision and recall, among other metrics\n",
        "print(metrics.classification_report(y_act, y_pred, labels=[\"normal\", \"other_tb\", \"ptb\"]))"
      ],
      "metadata": {
        "id": "HF3sG8-Csl2S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}